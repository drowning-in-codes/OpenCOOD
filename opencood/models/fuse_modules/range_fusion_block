from typing import List
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import einsum
from einops import rearrange, repeat


class RangeAttentionBlock(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.agent_att = AgentAttention(input_dim)
        self.local_att = LocalAttention(input_dim)
        self.conv1x1 = nn.Conv2d(input_dim, input_dim, kernel_size=1, bias=True)
        # self.conv3x3 = nn.Conv2d(input_dim, input_dim, kernel_size=3, padding=1, bias=False)

    @staticmethod
    def regroup(x, record_len):
        cum_sum_len = torch.cumsum(record_len, dim=0)
        split_x = torch.tensor_split(x, cum_sum_len[:-1].cpu())
        return split_x

    def forward(self, spatial_features, record_len):
        split_x = self.regroup(spatial_features, record_len)
        out = []
        # att = []
        for batch_spatial_feature in split_x:
            """
            combine agent and local attention
            """
            agent_feature = self.agent_att(spatial_features)
            local_feature = self.local_att(batch_spatial_feature[0].unsqueeze(0))
            local_feature = self.conv1x1(local_feature)
            ego_feature = torch.cat([agent_feature, local_feature], dim=1)
            out.append(ego_feature)
        out = torch.cat(out)
        return out


class AgentAttention(nn.Module):
    def __init__(self, input_dim, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(input_dim, input_dim // reduction),
            nn.ReLU(),
            nn.Linear(input_dim // reduction, input_dim),
            nn.Sigmoid()
        )
        # self.norm = nn.BatchNorm2d(intput_dim)
        self.conv1x1 = nn.Conv2d(input_dim, input_dim, 1)
        self.conv_att = nn.Sequential(
            nn.Conv2d(in_channels=input_dim, out_channels=input_dim, kernel_size=3, padding=1),
            nn.BatchNorm2d(input_dim, eps=1e-5, momentum=0.01, affine=True),
            nn.ReLU()
        )

    def forward(self, batch_spatial_feature):
        # get batch feature
        """
        agent-wise attention
        """
        # !TODO implement agent-wise attention
        att_vehicle = self.avg_pool(batch_spatial_feature).squeeze()
        att_vehicle = self.fc(att_vehicle).reshape(att_vehicle.shape[0], att_vehicle.shape[1], 1, 1)
        att_vehicle = att_vehicle * batch_spatial_feature
        att_vehicle = att_vehicle + batch_spatial_feature
        fuse_att = self.conv1x1(att_vehicle)
        pooling_max = torch.max(fuse_att, dim=0, keepdim=True)[0]
        pooling_ave = torch.mean(fuse_att, dim=0, keepdim=True)
        fuse_fea = pooling_max + pooling_ave
        out = self.conv_att(fuse_fea)
        return out

    def regroup(self, x, record_len):
        cum_sum_len = torch.cumsum(record_len, dim=0)
        split_x = torch.tensor_split(x, cum_sum_len[:-1].cpu())

        return split_x


class h_sigmoid(nn.Module):
    def __init__(self, inplace=True):
        super(h_sigmoid, self).__init__()
        self.relu = nn.ReLU6(inplace=inplace)

    def forward(self, x):
        return self.relu(x + 3) / 6


class h_swish(nn.Module):
    def __init__(self, inplace=True):
        super(h_swish, self).__init__()
        self.sigmoid = h_sigmoid(inplace=inplace)

    def forward(self, x):
        return x * self.sigmoid(x)


class CoordinateAttention(nn.Module):
    def __init__(self, inp, oup, reduction=16):
        super().__init__()
        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))

        mip = max(8, inp // reduction)
        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1)
        self.bn1 = nn.BatchNorm2d(mip)
        self.act = h_swish()

        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1)
        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1)

    def forward(self, x):
        identity = x

        n, c, h, w = x.size()
        x_h = self.pool_h(x)
        x_w = self.pool_w(x).permute(0, 1, 3, 2)

        y = torch.cat([x_h, x_w], dim=2)
        y = self.conv1(y)
        y = self.bn1(y)
        y = self.act(y)

        x_h, x_w = torch.split(y, [h, w], dim=2)
        x_w = x_w.permute(0, 1, 3, 2)
        a_h = self.conv_h(x_h).sigmoid()
        a_w = self.conv_w(x_w).sigmoid()
        out = identity * a_w * a_h
        return out


class LocalRangeAttention(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.conv1x1 = nn.Conv2d(input_dim, input_dim, kernel_size=1, bias=True)
        self.conv3x3 = nn.Conv2d(input_dim + 2, 1, kernel_size=3, padding=1, bias=False)
        self.conv2 = nn.Conv2d(4, 1, kernel_size=3, padding=1, bias=False)
        self.sigmoid = nn.Sigmoid()
        self.norm = nn.LayerNorm(input_dim)
        self.lam = nn.Parameter(torch.zeros(1))

    def forward(self, spatial_features):
        grid_h_batch, grid_w_batch, distance_tensor, = self.range_map(spatial_features)
        feature_out = self.conv1x1(spatial_features)
        feature_out = feature_out.permute(0, 2, 3, 1)
        norm_feature_out = self.norm(feature_out).permute(0, 3, 1, 2)

        out = torch.cat([norm_feature_out, grid_h_batch, grid_w_batch], dim=1)
        max_output = torch.max(out, dim=1, keepdim=True)[0]
        avg_output = torch.mean(out, dim=1, keepdim=True)
        conv_output = self.conv3x3(out)

        out = torch.cat([max_output, avg_output, conv_output, distance_tensor], dim=1)
        attn = self.sigmoid(self.conv2(out))
        attn = attn * self.lam
        out = attn * feature_out.permute(0, 3, 1, 2)
        out = out + feature_out.permute(0, 3, 1, 2)
        return out

    def range_map(self, spatial_features):
        # (H,W) distance map
        H, W = spatial_features.shape[-2:]

        lin_h = torch.linspace(0, H - 1, H).cuda()
        lin_w = torch.linspace(0, W - 1, W).cuda()
        y, x = torch.meshgrid(lin_h, lin_w)

        y = torch.abs(y - H / 2 + 0.5) if H % 2 == 1 else torch.abs(y - H / 2)
        x = torch.abs(x - W / 2 + 0.5) if W % 2 == 1 else torch.abs(x - W / 2)

        y = y / float(H // 2)
        x = x / float(W // 2)
        distance_tensor = torch.sqrt(x ** 2 + y ** 2).unsqueeze(0).unsqueeze(0).repeat(spatial_features.shape[0], 1, 1,
                                                                                       1)
        grid_h_batch = y.unsqueeze(0).unsqueeze(0).repeat(spatial_features.shape[0], 1, 1, 1)
        grid_w_batch = x.unsqueeze(0).unsqueeze(0).repeat(spatial_features.shape[0], 1, 1, 1)

        return grid_h_batch, grid_w_batch, distance_tensor


class LocalAttention(nn.Module):
    """
    implement local attention with range encoding
    """

    def __init__(self, input_dim):
        super().__init__()

        self.ca = CoordinateAttention(input_dim, input_dim)
        self.lra = LocalRangeAttention(input_dim)

    def forward(self, spatial_features):  # [cavs,C,H,W]
        coord_out = self.ca(spatial_features)
        lra_out = self.lra(spatial_features)
        out = torch.cat([lra_out, coord_out], dim=1)
        return out
